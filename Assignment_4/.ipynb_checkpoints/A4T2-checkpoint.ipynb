{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AybCwCfAKPDs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('datasets0/Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YJP_J-BPPZ7c"
   },
   "outputs": [],
   "source": [
    "df.drop(['UserId', 'Id', 'ProductId', 'ProfileName', 'Time', 'HelpfulnessNumerator', 'HelpfulnessDenominator'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OXcyQz_5Ll16"
   },
   "outputs": [],
   "source": [
    "df_train = df[55000:59999]\n",
    "df_valid = df[250000:251000]\n",
    "df_test = df[251001:252000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1dqQdRTwLqL7",
    "outputId": "47176ac5-20a7-4a69-cbca-8f0e7f52e1cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55000</th>\n",
       "      <td>1</td>\n",
       "      <td>Worst snack I ever tasted!</td>\n",
       "      <td>These are definitely the worst snack I have ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55001</th>\n",
       "      <td>2</td>\n",
       "      <td>Very Disappointing</td>\n",
       "      <td>Based on the reviews I thought I'd give the Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55002</th>\n",
       "      <td>4</td>\n",
       "      <td>Delicious, but a little salty</td>\n",
       "      <td>Like other reviewers have said, these are a li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55003</th>\n",
       "      <td>5</td>\n",
       "      <td>GF snacks, \"Just the Cheese\"</td>\n",
       "      <td>Yay! I used to be able to find these at local ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55004</th>\n",
       "      <td>2</td>\n",
       "      <td>will not re-order</td>\n",
       "      <td>I was expecting something better than what arr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Score                        Summary  \\\n",
       "55000      1     Worst snack I ever tasted!   \n",
       "55001      2             Very Disappointing   \n",
       "55002      4  Delicious, but a little salty   \n",
       "55003      5   GF snacks, \"Just the Cheese\"   \n",
       "55004      2              will not re-order   \n",
       "\n",
       "                                                    Text  \n",
       "55000  These are definitely the worst snack I have ev...  \n",
       "55001  Based on the reviews I thought I'd give the Wi...  \n",
       "55002  Like other reviewers have said, these are a li...  \n",
       "55003  Yay! I used to be able to find these at local ...  \n",
       "55004  I was expecting something better than what arr...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgPHZrOwSXcX",
    "outputId": "2d591d92-4d39-4293-8c96-929994cd84d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (4.16.2)\n",
      "Requirement already satisfied: filelock in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from transformers) (2022.1.18)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: requests in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from transformers) (0.11.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from transformers) (4.60.0)\n",
      "Requirement already satisfied: sacremoses in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from transformers) (5.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: click in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: six in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from sacremoses->transformers) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33JsnLZsNHWF",
    "outputId": "fbb6e786-4053-4542-da38-09efcbe22ca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "Device name: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RHdDNH6b3Q7"
   },
   "source": [
    "## Tokenization and Input Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oUDNHqIvNMee"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Em3EjWbFRHVx",
    "outputId": "6b4174c8-be94-4445-9ab2-379391fada9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.\n",
      "Processed:  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than most.\n"
     ]
    }
   ],
   "source": [
    "# Print sentence 0\n",
    "print('Original: ', df['Text'][0])\n",
    "print('Processed: ', text_preprocessing(df['Text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "93e47265d4994aa789abed0d50def9b3",
      "e2b6e0cd20794e22940abeeb42cc8e96",
      "599dce4954174f2b8909015d4c377290",
      "5e767bd5985044f888d84bd31230738c",
      "7959978aa50b4ebf9441f02615f1294d",
      "452f0140f7114b91adbfa09ecb3fb56c",
      "c13f3c74b4804dc89c5c89ed9b81b202",
      "8330658fd0824df29ba8e8450b787497",
      "abdfcfab69364a65a8233b0389266d01",
      "affa2a97c9c245d59365f74bce6b9772",
      "af440b9acaff473e8269ae3944d693e9",
      "8f82b402fd344929814a2dce4aacf700",
      "4ba590880552402b97ae6c43a1b2d3c5",
      "3d79ec161c8b4336b1daf0edb9235215",
      "5b9737421df24fe0bdde038e8e14e8b4",
      "1655c36f82c840278690f1070561b072",
      "e526c559a5bb4ec1ad552ada9a7a8958",
      "8c919b6325354ec4abddc7aaebb445b4",
      "3dda98c8377844138d4624931f054491",
      "7c50bf70806c478fa48df1df201ec733",
      "d1b6df08e9b24e96a67a995509a2e10d",
      "fe73813b431e4475bdb0972f16815b2a",
      "29f751fc3d35416b88a2d6a524578b63",
      "487f9e5fe119446a897a3a95ac38c65d",
      "a430ffcaba4145439221bddadc477815",
      "aed444330bf64b29aa99f43fa835473e",
      "7f163878271e48f1a758bc24d43e5978",
      "aebeca6d11564533b0e2885028ac2c32",
      "8243c1bcf44146b999b03420bb2b8e66",
      "1e510cb422654cc7af47d5fe066c5827",
      "4913a94fa16044e6b243aebcb64e6a31",
      "d7385c515c054a41be7896dbec63c823",
      "50f6cf48e9584298bbc1222cae097058"
     ]
    },
    "id": "TbJ9zNj9R4hW",
    "outputId": "29be256b-1fe9-4fc9-e196-16bd951431a6"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Create a function to tokenize a set of texts\n",
    "def preprocessing_for_bert(data):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent[:MAX_LEN]),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,             # Max length to truncate/pad\n",
    "            padding='max_length',           # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WmDgDDfkY7C2",
    "outputId": "d678d8b8-f0b3-4e84-9292-eda9f49997e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# Specify `MAX_LEN`\n",
    "MAX_LEN = 512\n",
    "\n",
    "# Print sentence 0 and its encoded token ids\n",
    "# token_ids = list(preprocessing_for_bert(df['Text'])[0].squeeze().numpy())\n",
    "# print('Original: ', df['Text'][0])\n",
    "# print('Token IDs: ', token_ids)\n",
    "\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(df_train['Text'])\n",
    "val_inputs, val_masks = preprocessing_for_bert(df_valid['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MXh1CweybuSa"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor((df_train['Score']-1).to_numpy())\n",
    "val_labels = torch.tensor((df_valid['Score']-1).to_numpy())\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 1\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtF5KDxtb69Q"
   },
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gqFcAVA3gfJP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.7 ms, sys: 76 Âµs, total: 25.7 ms\n",
      "Wall time: 25.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "# Create the BertClassfier class\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 50, 5\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "G6wtwgUCiNwp"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def initialize_model(epochs=4):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=5e-5,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4VheXWv9iY18"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"\n",
    "    Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "    \"\"\"\n",
    "    Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "y5QFFGOfiqev"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   1.091719   |     -      |     -     |   2.01   \n",
      "   1    |   40    |   1.000368   |     -      |     -     |   1.79   \n",
      "   1    |   60    |   1.206721   |     -      |     -     |   1.79   \n",
      "   1    |   80    |   1.074554   |     -      |     -     |   1.79   \n",
      "   1    |   100   |   2.835291   |     -      |     -     |   1.79   \n",
      "   1    |   120   |   1.912116   |     -      |     -     |   1.79   \n",
      "   1    |   140   |   1.380631   |     -      |     -     |   1.79   \n",
      "   1    |   160   |   1.648755   |     -      |     -     |   1.79   \n",
      "   1    |   180   |   1.611965   |     -      |     -     |   1.79   \n",
      "   1    |   200   |   1.922638   |     -      |     -     |   1.80   \n",
      "   1    |   220   |   2.131125   |     -      |     -     |   1.81   \n",
      "   1    |   240   |   1.834090   |     -      |     -     |   1.81   \n",
      "   1    |   260   |   0.844512   |     -      |     -     |   1.79   \n",
      "   1    |   280   |   2.184036   |     -      |     -     |   1.79   \n",
      "   1    |   300   |   1.466281   |     -      |     -     |   1.80   \n",
      "   1    |   320   |   2.712799   |     -      |     -     |   1.80   \n",
      "   1    |   340   |   1.683134   |     -      |     -     |   1.79   \n",
      "   1    |   360   |   1.946594   |     -      |     -     |   1.80   \n",
      "   1    |   380   |   0.972534   |     -      |     -     |   1.80   \n",
      "   1    |   400   |   2.079800   |     -      |     -     |   1.80   \n",
      "   1    |   420   |   1.746191   |     -      |     -     |   1.80   \n",
      "   1    |   440   |   1.853139   |     -      |     -     |   1.80   \n",
      "   1    |   460   |   1.028534   |     -      |     -     |   1.80   \n",
      "   1    |   480   |   1.553051   |     -      |     -     |   1.80   \n",
      "   1    |   500   |   1.039326   |     -      |     -     |   1.82   \n",
      "   1    |   520   |   1.368109   |     -      |     -     |   1.82   \n",
      "   1    |   540   |   1.586445   |     -      |     -     |   1.82   \n",
      "   1    |   560   |   1.660442   |     -      |     -     |   1.82   \n",
      "   1    |   580   |   1.039953   |     -      |     -     |   1.82   \n",
      "   1    |   600   |   2.615822   |     -      |     -     |   1.82   \n",
      "   1    |   620   |   1.295904   |     -      |     -     |   1.82   \n",
      "   1    |   640   |   1.101021   |     -      |     -     |   1.82   \n",
      "   1    |   660   |   1.118688   |     -      |     -     |   1.80   \n",
      "   1    |   680   |   2.956953   |     -      |     -     |   1.82   \n",
      "   1    |   700   |   1.984166   |     -      |     -     |   1.82   \n",
      "   1    |   720   |   2.501569   |     -      |     -     |   1.82   \n",
      "   1    |   740   |   1.399934   |     -      |     -     |   1.83   \n",
      "   1    |   760   |   1.272555   |     -      |     -     |   1.83   \n",
      "   1    |   780   |   1.905819   |     -      |     -     |   1.83   \n",
      "   1    |   800   |   1.038636   |     -      |     -     |   1.83   \n",
      "   1    |   820   |   2.591879   |     -      |     -     |   1.83   \n",
      "   1    |   840   |   1.319714   |     -      |     -     |   1.83   \n",
      "   1    |   860   |   2.235904   |     -      |     -     |   1.83   \n",
      "   1    |   880   |   1.801467   |     -      |     -     |   1.83   \n",
      "   1    |   900   |   1.853417   |     -      |     -     |   1.83   \n",
      "   1    |   920   |   1.774244   |     -      |     -     |   1.83   \n",
      "   1    |   940   |   1.555800   |     -      |     -     |   1.83   \n",
      "   1    |   960   |   2.252388   |     -      |     -     |   1.83   \n",
      "   1    |   980   |   1.508139   |     -      |     -     |   1.83   \n",
      "   1    |  1000   |   1.838773   |     -      |     -     |   1.83   \n",
      "   1    |  1020   |   1.251541   |     -      |     -     |   1.83   \n",
      "   1    |  1040   |   1.332827   |     -      |     -     |   1.83   \n",
      "   1    |  1060   |   2.730415   |     -      |     -     |   1.83   \n",
      "   1    |  1080   |   0.798080   |     -      |     -     |   1.83   \n",
      "   1    |  1100   |   1.339306   |     -      |     -     |   1.83   \n",
      "   1    |  1120   |   1.413850   |     -      |     -     |   1.83   \n",
      "   1    |  1140   |   1.609745   |     -      |     -     |   1.83   \n",
      "   1    |  1160   |   1.985775   |     -      |     -     |   1.83   \n",
      "   1    |  1180   |   2.392657   |     -      |     -     |   1.83   \n",
      "   1    |  1200   |   1.283620   |     -      |     -     |   1.84   \n",
      "   1    |  1220   |   2.263027   |     -      |     -     |   1.84   \n",
      "   1    |  1240   |   2.446035   |     -      |     -     |   1.84   \n",
      "   1    |  1260   |   0.957955   |     -      |     -     |   1.84   \n",
      "   1    |  1280   |   2.856506   |     -      |     -     |   1.84   \n",
      "   1    |  1300   |   1.547813   |     -      |     -     |   1.84   \n",
      "   1    |  1320   |   0.779093   |     -      |     -     |   1.84   \n",
      "   1    |  1340   |   1.132160   |     -      |     -     |   1.85   \n",
      "   1    |  1360   |   1.304689   |     -      |     -     |   1.83   \n",
      "   1    |  1380   |   1.791847   |     -      |     -     |   1.83   \n",
      "   1    |  1400   |   1.986528   |     -      |     -     |   1.83   \n",
      "   1    |  1420   |   1.774916   |     -      |     -     |   1.82   \n",
      "   1    |  1440   |   2.551527   |     -      |     -     |   1.85   \n",
      "   1    |  1460   |   1.347536   |     -      |     -     |   1.86   \n",
      "   1    |  1480   |   1.721711   |     -      |     -     |   1.85   \n",
      "   1    |  1500   |   2.308069   |     -      |     -     |   1.85   \n",
      "   1    |  1520   |   1.267043   |     -      |     -     |   1.85   \n",
      "   1    |  1540   |   2.940397   |     -      |     -     |   1.85   \n",
      "   1    |  1560   |   3.122865   |     -      |     -     |   1.84   \n",
      "   1    |  1580   |   1.980048   |     -      |     -     |   1.85   \n",
      "   1    |  1600   |   2.024774   |     -      |     -     |   1.85   \n",
      "   1    |  1620   |   1.253646   |     -      |     -     |   1.85   \n",
      "   1    |  1640   |   1.966482   |     -      |     -     |   1.85   \n",
      "   1    |  1660   |   1.229567   |     -      |     -     |   1.86   \n",
      "   1    |  1680   |   1.304135   |     -      |     -     |   1.85   \n",
      "   1    |  1700   |   1.579134   |     -      |     -     |   1.85   \n",
      "   1    |  1720   |   2.004795   |     -      |     -     |   1.86   \n",
      "   1    |  1740   |   0.824516   |     -      |     -     |   1.86   \n",
      "   1    |  1760   |   1.547813   |     -      |     -     |   1.85   \n",
      "   1    |  1780   |   1.696700   |     -      |     -     |   1.86   \n",
      "   1    |  1800   |   1.905505   |     -      |     -     |   1.85   \n",
      "   1    |  1820   |   2.828407   |     -      |     -     |   1.88   \n",
      "   1    |  1840   |   2.583188   |     -      |     -     |   1.85   \n",
      "   1    |  1860   |   2.008033   |     -      |     -     |   1.85   \n",
      "   1    |  1880   |   1.501626   |     -      |     -     |   1.86   \n",
      "   1    |  1900   |   1.007735   |     -      |     -     |   1.85   \n",
      "   1    |  1920   |   2.632700   |     -      |     -     |   1.86   \n",
      "   1    |  1940   |   2.307146   |     -      |     -     |   1.85   \n",
      "   1    |  1960   |   1.696481   |     -      |     -     |   1.85   \n",
      "   1    |  1980   |   1.661719   |     -      |     -     |   1.85   \n",
      "   1    |  2000   |   2.976577   |     -      |     -     |   1.84   \n",
      "   1    |  2020   |   1.801698   |     -      |     -     |   1.83   \n",
      "   1    |  2040   |   2.068638   |     -      |     -     |   1.84   \n",
      "   1    |  2060   |   1.865365   |     -      |     -     |   1.85   \n",
      "   1    |  2080   |   1.914231   |     -      |     -     |   1.85   \n",
      "   1    |  2100   |   1.523160   |     -      |     -     |   1.85   \n",
      "   1    |  2120   |   1.223508   |     -      |     -     |   1.85   \n",
      "   1    |  2140   |   1.296522   |     -      |     -     |   1.86   \n",
      "   1    |  2160   |   2.497996   |     -      |     -     |   1.84   \n",
      "   1    |  2180   |   2.815616   |     -      |     -     |   1.85   \n",
      "   1    |  2200   |   1.535475   |     -      |     -     |   1.86   \n",
      "   1    |  2220   |   1.654205   |     -      |     -     |   1.86   \n",
      "   1    |  2240   |   1.443473   |     -      |     -     |   1.87   \n",
      "   1    |  2260   |   1.370062   |     -      |     -     |   1.86   \n",
      "   1    |  2280   |   1.491886   |     -      |     -     |   1.85   \n",
      "   1    |  2300   |   1.184758   |     -      |     -     |   1.85   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1    |  2320   |   1.351143   |     -      |     -     |   1.85   \n",
      "   1    |  2340   |   1.105782   |     -      |     -     |   1.85   \n",
      "   1    |  2360   |   1.133818   |     -      |     -     |   1.85   \n",
      "   1    |  2380   |   1.244341   |     -      |     -     |   1.86   \n",
      "   1    |  2400   |   1.525143   |     -      |     -     |   1.86   \n",
      "   1    |  2420   |   1.019489   |     -      |     -     |   1.86   \n",
      "   1    |  2440   |   0.993152   |     -      |     -     |   1.85   \n",
      "   1    |  2460   |   1.185902   |     -      |     -     |   1.85   \n",
      "   1    |  2480   |   1.145412   |     -      |     -     |   1.86   \n",
      "   1    |  2500   |   0.833168   |     -      |     -     |   1.86   \n",
      "   1    |  2520   |   1.341209   |     -      |     -     |   1.86   \n",
      "   1    |  2540   |   1.149671   |     -      |     -     |   1.86   \n",
      "   1    |  2560   |   1.785515   |     -      |     -     |   1.84   \n",
      "   1    |  2580   |   1.047250   |     -      |     -     |   1.84   \n",
      "   1    |  2600   |   1.540309   |     -      |     -     |   1.85   \n",
      "   1    |  2620   |   1.029646   |     -      |     -     |   1.85   \n",
      "   1    |  2640   |   1.170681   |     -      |     -     |   1.85   \n",
      "   1    |  2660   |   0.821656   |     -      |     -     |   1.84   \n",
      "   1    |  2680   |   1.723087   |     -      |     -     |   1.85   \n",
      "   1    |  2700   |   1.434712   |     -      |     -     |   1.85   \n",
      "   1    |  2720   |   1.218476   |     -      |     -     |   1.85   \n",
      "   1    |  2740   |   1.000061   |     -      |     -     |   1.85   \n",
      "   1    |  2760   |   1.318772   |     -      |     -     |   1.85   \n",
      "   1    |  2780   |   1.702708   |     -      |     -     |   1.84   \n",
      "   1    |  2800   |   1.426009   |     -      |     -     |   1.84   \n",
      "   1    |  2820   |   1.909841   |     -      |     -     |   1.83   \n",
      "   1    |  2840   |   0.981715   |     -      |     -     |   1.85   \n",
      "   1    |  2860   |   1.241117   |     -      |     -     |   1.85   \n",
      "   1    |  2880   |   3.121801   |     -      |     -     |   1.84   \n",
      "   1    |  2900   |   1.771631   |     -      |     -     |   1.84   \n",
      "   1    |  2920   |   1.631577   |     -      |     -     |   1.83   \n",
      "   1    |  2940   |   1.834833   |     -      |     -     |   1.83   \n",
      "   1    |  2960   |   1.810517   |     -      |     -     |   1.84   \n",
      "   1    |  2980   |   2.748933   |     -      |     -     |   1.83   \n",
      "   1    |  3000   |   2.071977   |     -      |     -     |   1.84   \n",
      "   1    |  3020   |   2.054110   |     -      |     -     |   1.83   \n",
      "   1    |  3040   |   2.236459   |     -      |     -     |   1.83   \n",
      "   1    |  3060   |   1.499511   |     -      |     -     |   1.83   \n",
      "   1    |  3080   |   1.927265   |     -      |     -     |   1.83   \n",
      "   1    |  3100   |   1.015270   |     -      |     -     |   1.83   \n",
      "   1    |  3120   |   1.856520   |     -      |     -     |   1.83   \n",
      "   1    |  3140   |   2.324244   |     -      |     -     |   1.83   \n",
      "   1    |  3160   |   1.003873   |     -      |     -     |   1.84   \n",
      "   1    |  3180   |   1.511449   |     -      |     -     |   1.84   \n",
      "   1    |  3200   |   0.974892   |     -      |     -     |   1.84   \n",
      "   1    |  3220   |   2.155509   |     -      |     -     |   1.84   \n",
      "   1    |  3240   |   2.152997   |     -      |     -     |   1.84   \n",
      "   1    |  3260   |   1.028007   |     -      |     -     |   1.84   \n",
      "   1    |  3280   |   1.909623   |     -      |     -     |   1.83   \n",
      "   1    |  3300   |   2.015964   |     -      |     -     |   1.83   \n",
      "   1    |  3320   |   1.295300   |     -      |     -     |   1.83   \n",
      "   1    |  3340   |   1.791347   |     -      |     -     |   1.84   \n",
      "   1    |  3360   |   1.354665   |     -      |     -     |   1.84   \n",
      "   1    |  3380   |   0.597374   |     -      |     -     |   1.83   \n",
      "   1    |  3400   |   2.234899   |     -      |     -     |   1.83   \n",
      "   1    |  3420   |   2.116928   |     -      |     -     |   1.84   \n",
      "   1    |  3440   |   2.249024   |     -      |     -     |   1.83   \n",
      "   1    |  3460   |   1.245249   |     -      |     -     |   1.85   \n",
      "   1    |  3480   |   2.082957   |     -      |     -     |   1.84   \n",
      "   1    |  3500   |   2.165839   |     -      |     -     |   1.84   \n",
      "   1    |  3520   |   1.523541   |     -      |     -     |   1.85   \n",
      "   1    |  3540   |   1.990337   |     -      |     -     |   1.86   \n",
      "   1    |  3560   |   1.880636   |     -      |     -     |   1.87   \n",
      "   1    |  3580   |   1.531074   |     -      |     -     |   1.85   \n",
      "   1    |  3600   |   1.964234   |     -      |     -     |   1.86   \n",
      "   1    |  3620   |   1.422923   |     -      |     -     |   1.85   \n",
      "   1    |  3640   |   2.256316   |     -      |     -     |   1.85   \n",
      "   1    |  3660   |   0.782950   |     -      |     -     |   1.86   \n",
      "   1    |  3680   |   1.856666   |     -      |     -     |   1.86   \n",
      "   1    |  3700   |   1.321124   |     -      |     -     |   1.86   \n",
      "   1    |  3720   |   1.515751   |     -      |     -     |   1.86   \n",
      "   1    |  3740   |   2.842141   |     -      |     -     |   1.85   \n",
      "   1    |  3760   |   1.582850   |     -      |     -     |   1.87   \n",
      "   1    |  3780   |   1.713728   |     -      |     -     |   1.87   \n",
      "   1    |  3800   |   2.208859   |     -      |     -     |   1.86   \n",
      "   1    |  3820   |   2.418525   |     -      |     -     |   1.86   \n",
      "   1    |  3840   |   1.470423   |     -      |     -     |   1.86   \n",
      "   1    |  3860   |   1.758653   |     -      |     -     |   1.84   \n",
      "   1    |  3880   |   2.279281   |     -      |     -     |   1.86   \n",
      "   1    |  3900   |   1.783513   |     -      |     -     |   1.86   \n",
      "   1    |  3920   |   1.983739   |     -      |     -     |   1.86   \n",
      "   1    |  3940   |   1.562335   |     -      |     -     |   1.86   \n",
      "   1    |  3960   |   1.564518   |     -      |     -     |   1.87   \n",
      "   1    |  3980   |   1.568151   |     -      |     -     |   1.88   \n",
      "   1    |  4000   |   2.403832   |     -      |     -     |   1.85   \n",
      "   1    |  4020   |   1.989352   |     -      |     -     |   1.85   \n",
      "   1    |  4040   |   2.013637   |     -      |     -     |   1.84   \n",
      "   1    |  4060   |   1.899425   |     -      |     -     |   1.85   \n",
      "   1    |  4080   |   1.195626   |     -      |     -     |   1.85   \n",
      "   1    |  4100   |   1.433215   |     -      |     -     |   1.85   \n",
      "   1    |  4120   |   2.330854   |     -      |     -     |   1.86   \n",
      "   1    |  4140   |   1.646511   |     -      |     -     |   1.86   \n",
      "   1    |  4160   |   1.718751   |     -      |     -     |   1.86   \n",
      "   1    |  4180   |   2.756365   |     -      |     -     |   1.87   \n",
      "   1    |  4200   |   1.822686   |     -      |     -     |   1.85   \n",
      "   1    |  4220   |   1.905555   |     -      |     -     |   1.86   \n",
      "   1    |  4240   |   1.702279   |     -      |     -     |   1.86   \n",
      "   1    |  4260   |   1.707606   |     -      |     -     |   1.84   \n",
      "   1    |  4280   |   1.849893   |     -      |     -     |   1.83   \n",
      "   1    |  4300   |   1.803462   |     -      |     -     |   1.83   \n",
      "   1    |  4320   |   2.234287   |     -      |     -     |   1.85   \n",
      "   1    |  4340   |   2.172250   |     -      |     -     |   1.85   \n",
      "   1    |  4360   |   1.619329   |     -      |     -     |   1.86   \n",
      "   1    |  4380   |   0.806754   |     -      |     -     |   1.85   \n",
      "   1    |  4400   |   1.590370   |     -      |     -     |   1.84   \n",
      "   1    |  4420   |   1.544694   |     -      |     -     |   1.85   \n",
      "   1    |  4440   |   1.313404   |     -      |     -     |   1.86   \n",
      "   1    |  4460   |   3.235002   |     -      |     -     |   1.85   \n",
      "   1    |  4480   |   2.265188   |     -      |     -     |   1.86   \n",
      "   1    |  4500   |   1.628678   |     -      |     -     |   1.86   \n",
      "   1    |  4520   |   0.961208   |     -      |     -     |   1.86   \n",
      "   1    |  4540   |   1.367634   |     -      |     -     |   1.86   \n",
      "   1    |  4560   |   2.923775   |     -      |     -     |   1.86   \n",
      "   1    |  4580   |   2.495405   |     -      |     -     |   1.86   \n",
      "   1    |  4600   |   1.841616   |     -      |     -     |   1.86   \n",
      "   1    |  4620   |   1.929543   |     -      |     -     |   1.85   \n",
      "   1    |  4640   |   1.923727   |     -      |     -     |   1.86   \n",
      "   1    |  4660   |   1.642963   |     -      |     -     |   1.84   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1    |  4680   |   2.010132   |     -      |     -     |   1.85   \n",
      "   1    |  4700   |   1.274155   |     -      |     -     |   1.86   \n",
      "   1    |  4720   |   1.374869   |     -      |     -     |   1.85   \n",
      "   1    |  4740   |   1.622164   |     -      |     -     |   1.86   \n",
      "   1    |  4760   |   3.111630   |     -      |     -     |   1.86   \n",
      "   1    |  4780   |   2.603366   |     -      |     -     |   1.85   \n",
      "   1    |  4800   |   1.875458   |     -      |     -     |   1.85   \n",
      "   1    |  4820   |   1.503363   |     -      |     -     |   1.86   \n",
      "   1    |  4840   |   1.874094   |     -      |     -     |   1.85   \n",
      "   1    |  4860   |   1.653436   |     -      |     -     |   1.86   \n",
      "   1    |  4880   |   1.480682   |     -      |     -     |   1.86   \n",
      "   1    |  4900   |   1.693346   |     -      |     -     |   1.86   \n",
      "   1    |  4920   |   1.001472   |     -      |     -     |   1.86   \n",
      "   1    |  4940   |   1.513298   |     -      |     -     |   1.85   \n",
      "   1    |  4960   |   2.306694   |     -      |     -     |   1.84   \n",
      "   1    |  4980   |   1.811250   |     -      |     -     |   1.85   \n",
      "   1    |  4998   |   2.264173   |     -      |     -     |   1.67   \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   1.725192   |  2.057498  |   60.30   |  483.42  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   1.492599   |     -      |     -     |   1.97   \n",
      "   2    |   40    |   2.421735   |     -      |     -     |   1.84   \n",
      "   2    |   60    |   2.363667   |     -      |     -     |   1.84   \n",
      "   2    |   80    |   2.341921   |     -      |     -     |   1.84   \n",
      "   2    |   100   |   1.918148   |     -      |     -     |   1.83   \n",
      "   2    |   120   |   1.886499   |     -      |     -     |   1.83   \n",
      "   2    |   140   |   0.955473   |     -      |     -     |   1.83   \n",
      "   2    |   160   |   1.296694   |     -      |     -     |   1.84   \n",
      "   2    |   180   |   2.193168   |     -      |     -     |   1.85   \n",
      "   2    |   200   |   2.019656   |     -      |     -     |   1.84   \n",
      "   2    |   220   |   0.999991   |     -      |     -     |   1.87   \n",
      "   2    |   240   |   2.707039   |     -      |     -     |   1.86   \n",
      "   2    |   260   |   2.581810   |     -      |     -     |   1.86   \n",
      "   2    |   280   |   0.739781   |     -      |     -     |   1.85   \n",
      "   2    |   300   |   1.040221   |     -      |     -     |   1.85   \n",
      "   2    |   320   |   1.299940   |     -      |     -     |   1.85   \n",
      "   2    |   340   |   1.990534   |     -      |     -     |   1.86   \n",
      "   2    |   360   |   1.925209   |     -      |     -     |   1.85   \n",
      "   2    |   380   |   1.332441   |     -      |     -     |   1.85   \n",
      "   2    |   400   |   2.356034   |     -      |     -     |   1.86   \n",
      "   2    |   420   |   2.423320   |     -      |     -     |   1.86   \n",
      "   2    |   440   |   1.799129   |     -      |     -     |   1.86   \n",
      "   2    |   460   |   1.198916   |     -      |     -     |   1.84   \n",
      "   2    |   480   |   1.787677   |     -      |     -     |   1.83   \n",
      "   2    |   500   |   1.538563   |     -      |     -     |   1.83   \n",
      "   2    |   520   |   2.737278   |     -      |     -     |   1.84   \n",
      "   2    |   540   |   2.080590   |     -      |     -     |   1.83   \n",
      "   2    |   560   |   1.496485   |     -      |     -     |   1.83   \n",
      "   2    |   580   |   1.914114   |     -      |     -     |   1.84   \n",
      "   2    |   600   |   1.262854   |     -      |     -     |   1.86   \n",
      "   2    |   620   |   2.898627   |     -      |     -     |   1.84   \n",
      "   2    |   640   |   2.424720   |     -      |     -     |   1.83   \n",
      "   2    |   660   |   1.718766   |     -      |     -     |   1.86   \n",
      "   2    |   680   |   1.615298   |     -      |     -     |   1.86   \n",
      "   2    |   700   |   1.445217   |     -      |     -     |   1.86   \n",
      "   2    |   720   |   1.998883   |     -      |     -     |   1.86   \n",
      "   2    |   740   |   1.454655   |     -      |     -     |   1.84   \n",
      "   2    |   760   |   0.788553   |     -      |     -     |   1.86   \n",
      "   2    |   780   |   2.735264   |     -      |     -     |   1.85   \n",
      "   2    |   800   |   1.940483   |     -      |     -     |   1.86   \n",
      "   2    |   820   |   1.739765   |     -      |     -     |   1.86   \n",
      "   2    |   840   |   2.399883   |     -      |     -     |   1.86   \n",
      "   2    |   860   |   1.156257   |     -      |     -     |   1.85   \n",
      "   2    |   880   |   1.052349   |     -      |     -     |   1.87   \n",
      "   2    |   900   |   2.282760   |     -      |     -     |   1.86   \n",
      "   2    |   920   |   1.732479   |     -      |     -     |   1.84   \n",
      "   2    |   940   |   1.116192   |     -      |     -     |   1.84   \n",
      "   2    |   960   |   1.317616   |     -      |     -     |   1.84   \n",
      "   2    |   980   |   1.449305   |     -      |     -     |   1.84   \n",
      "   2    |  1000   |   2.274607   |     -      |     -     |   1.85   \n",
      "   2    |  1020   |   2.121667   |     -      |     -     |   1.86   \n",
      "   2    |  1040   |   2.505080   |     -      |     -     |   1.87   \n",
      "   2    |  1060   |   1.963424   |     -      |     -     |   1.86   \n",
      "   2    |  1080   |   2.018756   |     -      |     -     |   1.85   \n",
      "   2    |  1100   |   1.284447   |     -      |     -     |   1.85   \n",
      "   2    |  1120   |   1.776683   |     -      |     -     |   1.86   \n",
      "   2    |  1140   |   1.899855   |     -      |     -     |   1.86   \n",
      "   2    |  1160   |   1.993706   |     -      |     -     |   1.86   \n",
      "   2    |  1180   |   1.757613   |     -      |     -     |   1.86   \n",
      "   2    |  1200   |   2.608368   |     -      |     -     |   1.85   \n",
      "   2    |  1220   |   2.076942   |     -      |     -     |   1.86   \n",
      "   2    |  1240   |   2.070900   |     -      |     -     |   1.86   \n",
      "   2    |  1260   |   2.218625   |     -      |     -     |   1.86   \n",
      "   2    |  1280   |   1.574004   |     -      |     -     |   1.86   \n",
      "   2    |  1300   |   1.632741   |     -      |     -     |   1.85   \n",
      "   2    |  1320   |   0.521750   |     -      |     -     |   1.85   \n",
      "   2    |  1340   |   2.221604   |     -      |     -     |   1.86   \n",
      "   2    |  1360   |   1.204559   |     -      |     -     |   1.86   \n",
      "   2    |  1380   |   2.472349   |     -      |     -     |   1.86   \n",
      "   2    |  1400   |   2.015580   |     -      |     -     |   1.86   \n",
      "   2    |  1420   |   1.658202   |     -      |     -     |   1.86   \n",
      "   2    |  1440   |   1.933571   |     -      |     -     |   1.85   \n",
      "   2    |  1460   |   1.775419   |     -      |     -     |   1.85   \n",
      "   2    |  1480   |   1.375529   |     -      |     -     |   1.86   \n",
      "   2    |  1500   |   2.011563   |     -      |     -     |   1.86   \n",
      "   2    |  1520   |   1.352402   |     -      |     -     |   1.86   \n",
      "   2    |  1540   |   1.225606   |     -      |     -     |   1.86   \n",
      "   2    |  1560   |   2.304775   |     -      |     -     |   1.85   \n",
      "   2    |  1580   |   1.567442   |     -      |     -     |   1.86   \n",
      "   2    |  1600   |   1.683658   |     -      |     -     |   1.85   \n",
      "   2    |  1620   |   1.248242   |     -      |     -     |   1.85   \n",
      "   2    |  1640   |   2.163552   |     -      |     -     |   1.86   \n",
      "   2    |  1660   |   2.711616   |     -      |     -     |   1.85   \n",
      "   2    |  1680   |   2.697950   |     -      |     -     |   1.85   \n",
      "   2    |  1700   |   2.028454   |     -      |     -     |   1.86   \n",
      "   2    |  1720   |   2.324429   |     -      |     -     |   1.86   \n",
      "   2    |  1740   |   1.709666   |     -      |     -     |   1.85   \n",
      "   2    |  1760   |   0.904649   |     -      |     -     |   1.83   \n",
      "   2    |  1780   |   1.171843   |     -      |     -     |   1.83   \n",
      "   2    |  1800   |   1.229892   |     -      |     -     |   1.84   \n",
      "   2    |  1820   |   1.763384   |     -      |     -     |   1.83   \n",
      "   2    |  1840   |   2.528100   |     -      |     -     |   1.83   \n",
      "   2    |  1860   |   2.097430   |     -      |     -     |   1.84   \n",
      "   2    |  1880   |   1.434842   |     -      |     -     |   1.84   \n",
      "   2    |  1900   |   1.468692   |     -      |     -     |   1.83   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2    |  1920   |   1.697224   |     -      |     -     |   1.83   \n",
      "   2    |  1940   |   1.966302   |     -      |     -     |   1.85   \n",
      "   2    |  1960   |   1.945139   |     -      |     -     |   1.85   \n",
      "   2    |  1980   |   1.008301   |     -      |     -     |   1.85   \n",
      "   2    |  2000   |   1.264858   |     -      |     -     |   1.87   \n",
      "   2    |  2020   |   2.444264   |     -      |     -     |   1.86   \n",
      "   2    |  2040   |   2.028978   |     -      |     -     |   1.85   \n",
      "   2    |  2060   |   1.880818   |     -      |     -     |   1.86   \n",
      "   2    |  2080   |   2.659186   |     -      |     -     |   1.85   \n",
      "   2    |  2100   |   1.874426   |     -      |     -     |   1.86   \n",
      "   2    |  2120   |   1.208565   |     -      |     -     |   1.85   \n",
      "   2    |  2140   |   2.273496   |     -      |     -     |   1.86   \n",
      "   2    |  2160   |   1.403143   |     -      |     -     |   1.85   \n",
      "   2    |  2180   |   0.966743   |     -      |     -     |   1.86   \n",
      "   2    |  2200   |   1.541843   |     -      |     -     |   1.85   \n",
      "   2    |  2220   |   1.843490   |     -      |     -     |   1.85   \n",
      "   2    |  2240   |   1.482438   |     -      |     -     |   1.85   \n",
      "   2    |  2260   |   2.229526   |     -      |     -     |   1.85   \n",
      "   2    |  2280   |   1.901951   |     -      |     -     |   1.87   \n",
      "   2    |  2300   |   1.623629   |     -      |     -     |   1.87   \n",
      "   2    |  2320   |   1.983241   |     -      |     -     |   1.86   \n",
      "   2    |  2340   |   2.220638   |     -      |     -     |   1.86   \n",
      "   2    |  2360   |   2.247784   |     -      |     -     |   1.85   \n",
      "   2    |  2380   |   1.501681   |     -      |     -     |   1.85   \n",
      "   2    |  2400   |   1.988742   |     -      |     -     |   1.85   \n",
      "   2    |  2420   |   1.509426   |     -      |     -     |   1.85   \n",
      "   2    |  2440   |   1.760086   |     -      |     -     |   1.85   \n",
      "   2    |  2460   |   1.430945   |     -      |     -     |   1.84   \n",
      "   2    |  2480   |   1.718614   |     -      |     -     |   1.84   \n",
      "   2    |  2500   |   1.539731   |     -      |     -     |   1.84   \n",
      "   2    |  2520   |   2.532919   |     -      |     -     |   1.84   \n",
      "   2    |  2540   |   1.440224   |     -      |     -     |   1.85   \n",
      "   2    |  2560   |   1.575685   |     -      |     -     |   1.86   \n",
      "   2    |  2580   |   1.504762   |     -      |     -     |   1.87   \n",
      "   2    |  2600   |   2.483672   |     -      |     -     |   1.84   \n",
      "   2    |  2620   |   1.477037   |     -      |     -     |   1.85   \n",
      "   2    |  2640   |   1.118735   |     -      |     -     |   1.85   \n",
      "   2    |  2660   |   0.840273   |     -      |     -     |   1.84   \n",
      "   2    |  2680   |   1.044567   |     -      |     -     |   1.83   \n",
      "   2    |  2700   |   3.092435   |     -      |     -     |   1.84   \n",
      "   2    |  2720   |   1.735866   |     -      |     -     |   1.86   \n",
      "   2    |  2740   |   1.839597   |     -      |     -     |   1.84   \n",
      "   2    |  2760   |   1.765928   |     -      |     -     |   1.84   \n",
      "   2    |  2780   |   1.787505   |     -      |     -     |   1.85   \n",
      "   2    |  2800   |   1.489210   |     -      |     -     |   1.86   \n",
      "   2    |  2820   |   1.522253   |     -      |     -     |   1.85   \n",
      "   2    |  2840   |   1.531263   |     -      |     -     |   1.86   \n",
      "   2    |  2860   |   1.268297   |     -      |     -     |   1.86   \n",
      "   2    |  2880   |   2.542632   |     -      |     -     |   1.85   \n",
      "   2    |  2900   |   1.537831   |     -      |     -     |   1.86   \n",
      "   2    |  2920   |   2.264138   |     -      |     -     |   1.85   \n",
      "   2    |  2940   |   1.481283   |     -      |     -     |   1.86   \n",
      "   2    |  2960   |   1.502681   |     -      |     -     |   1.87   \n",
      "   2    |  2980   |   1.766940   |     -      |     -     |   1.85   \n",
      "   2    |  3000   |   1.380967   |     -      |     -     |   1.85   \n",
      "   2    |  3020   |   2.517003   |     -      |     -     |   1.85   \n",
      "   2    |  3040   |   2.227899   |     -      |     -     |   1.85   \n",
      "   2    |  3060   |   1.029230   |     -      |     -     |   1.86   \n",
      "   2    |  3080   |   1.553221   |     -      |     -     |   1.86   \n",
      "   2    |  3100   |   0.989682   |     -      |     -     |   1.86   \n",
      "   2    |  3120   |   2.161637   |     -      |     -     |   1.85   \n",
      "   2    |  3140   |   2.325648   |     -      |     -     |   1.86   \n",
      "   2    |  3160   |   1.271167   |     -      |     -     |   1.86   \n",
      "   2    |  3180   |   1.224291   |     -      |     -     |   1.86   \n",
      "   2    |  3200   |   1.774805   |     -      |     -     |   1.84   \n",
      "   2    |  3220   |   2.223084   |     -      |     -     |   1.84   \n",
      "   2    |  3240   |   2.826459   |     -      |     -     |   1.86   \n",
      "   2    |  3260   |   2.137199   |     -      |     -     |   1.85   \n",
      "   2    |  3280   |   1.806425   |     -      |     -     |   1.86   \n",
      "   2    |  3300   |   0.728586   |     -      |     -     |   1.85   \n",
      "   2    |  3320   |   2.256680   |     -      |     -     |   1.86   \n",
      "   2    |  3340   |   1.784265   |     -      |     -     |   1.86   \n",
      "   2    |  3360   |   2.253092   |     -      |     -     |   1.87   \n",
      "   2    |  3380   |   1.819262   |     -      |     -     |   1.85   \n",
      "   2    |  3400   |   1.252401   |     -      |     -     |   1.86   \n",
      "   2    |  3420   |   1.466331   |     -      |     -     |   1.86   \n",
      "   2    |  3440   |   1.953880   |     -      |     -     |   1.85   \n",
      "   2    |  3460   |   1.068106   |     -      |     -     |   1.85   \n",
      "   2    |  3480   |   2.019521   |     -      |     -     |   1.85   \n",
      "   2    |  3500   |   1.487436   |     -      |     -     |   1.86   \n",
      "   2    |  3520   |   2.048602   |     -      |     -     |   1.86   \n",
      "   2    |  3540   |   1.047880   |     -      |     -     |   1.85   \n",
      "   2    |  3560   |   1.520285   |     -      |     -     |   1.85   \n",
      "   2    |  3580   |   2.285903   |     -      |     -     |   1.83   \n",
      "   2    |  3600   |   1.974337   |     -      |     -     |   1.85   \n",
      "   2    |  3620   |   2.048798   |     -      |     -     |   1.85   \n",
      "   2    |  3640   |   1.952260   |     -      |     -     |   1.84   \n",
      "   2    |  3660   |   1.114788   |     -      |     -     |   1.86   \n",
      "   2    |  3680   |   2.273866   |     -      |     -     |   1.86   \n",
      "   2    |  3700   |   1.562133   |     -      |     -     |   1.86   \n",
      "   2    |  3720   |   0.996737   |     -      |     -     |   1.86   \n",
      "   2    |  3740   |   1.220194   |     -      |     -     |   1.87   \n",
      "   2    |  3760   |   1.240662   |     -      |     -     |   1.86   \n",
      "   2    |  3780   |   3.039206   |     -      |     -     |   1.85   \n",
      "   2    |  3800   |   2.234754   |     -      |     -     |   1.86   \n",
      "   2    |  3820   |   3.472601   |     -      |     -     |   1.86   \n",
      "   2    |  3840   |   1.310704   |     -      |     -     |   1.87   \n",
      "   2    |  3860   |   1.513266   |     -      |     -     |   1.86   \n",
      "   2    |  3880   |   1.276550   |     -      |     -     |   1.85   \n",
      "   2    |  3900   |   1.008071   |     -      |     -     |   1.87   \n",
      "   2    |  3920   |   1.804871   |     -      |     -     |   1.85   \n",
      "   2    |  3940   |   1.323031   |     -      |     -     |   1.86   \n",
      "   2    |  3960   |   1.973133   |     -      |     -     |   1.86   \n",
      "   2    |  3980   |   0.720562   |     -      |     -     |   1.85   \n",
      "   2    |  4000   |   2.032193   |     -      |     -     |   1.85   \n",
      "   2    |  4020   |   1.765829   |     -      |     -     |   1.86   \n",
      "   2    |  4040   |   1.251396   |     -      |     -     |   1.85   \n",
      "   2    |  4060   |   2.041653   |     -      |     -     |   1.87   \n",
      "   2    |  4080   |   1.540205   |     -      |     -     |   1.86   \n",
      "   2    |  4100   |   1.814526   |     -      |     -     |   1.85   \n",
      "   2    |  4120   |   2.386410   |     -      |     -     |   1.84   \n",
      "   2    |  4140   |   1.540241   |     -      |     -     |   1.83   \n",
      "   2    |  4160   |   1.515649   |     -      |     -     |   1.85   \n",
      "   2    |  4180   |   2.567580   |     -      |     -     |   1.84   \n",
      "   2    |  4200   |   2.984854   |     -      |     -     |   1.84   \n",
      "   2    |  4220   |   1.076351   |     -      |     -     |   1.86   \n",
      "   2    |  4240   |   1.263642   |     -      |     -     |   1.86   \n",
      "   2    |  4260   |   1.919789   |     -      |     -     |   1.86   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2    |  4280   |   3.427265   |     -      |     -     |   1.86   \n",
      "   2    |  4300   |   1.782728   |     -      |     -     |   1.86   \n",
      "   2    |  4320   |   2.643244   |     -      |     -     |   1.86   \n",
      "   2    |  4340   |   1.056606   |     -      |     -     |   1.85   \n",
      "   2    |  4360   |   1.675422   |     -      |     -     |   1.85   \n",
      "   2    |  4380   |   2.177709   |     -      |     -     |   1.86   \n",
      "   2    |  4400   |   1.756992   |     -      |     -     |   1.85   \n",
      "   2    |  4420   |   1.492702   |     -      |     -     |   1.84   \n",
      "   2    |  4440   |   2.075267   |     -      |     -     |   1.85   \n",
      "   2    |  4460   |   2.197077   |     -      |     -     |   1.86   \n",
      "   2    |  4480   |   2.016063   |     -      |     -     |   1.86   \n",
      "   2    |  4500   |   1.952192   |     -      |     -     |   1.85   \n",
      "   2    |  4520   |   1.269790   |     -      |     -     |   1.84   \n",
      "   2    |  4540   |   1.269663   |     -      |     -     |   1.85   \n",
      "   2    |  4560   |   1.216948   |     -      |     -     |   1.85   \n",
      "   2    |  4580   |   1.746335   |     -      |     -     |   1.84   \n",
      "   2    |  4600   |   2.446820   |     -      |     -     |   1.84   \n",
      "   2    |  4620   |   1.738305   |     -      |     -     |   1.84   \n",
      "   2    |  4640   |   1.958834   |     -      |     -     |   1.86   \n",
      "   2    |  4660   |   1.740029   |     -      |     -     |   1.87   \n",
      "   2    |  4680   |   2.245449   |     -      |     -     |   1.85   \n",
      "   2    |  4700   |   1.976312   |     -      |     -     |   1.87   \n",
      "   2    |  4720   |   1.173047   |     -      |     -     |   1.87   \n",
      "   2    |  4740   |   2.260288   |     -      |     -     |   1.85   \n",
      "   2    |  4760   |   1.270178   |     -      |     -     |   1.84   \n",
      "   2    |  4780   |   1.174562   |     -      |     -     |   1.84   \n",
      "   2    |  4800   |   2.829896   |     -      |     -     |   1.83   \n",
      "   2    |  4820   |   1.422338   |     -      |     -     |   1.85   \n",
      "   2    |  4840   |   1.694725   |     -      |     -     |   1.86   \n",
      "   2    |  4860   |   1.324549   |     -      |     -     |   1.85   \n",
      "   2    |  4880   |   2.682795   |     -      |     -     |   1.87   \n",
      "   2    |  4900   |   1.704413   |     -      |     -     |   1.84   \n",
      "   2    |  4920   |   1.571285   |     -      |     -     |   1.83   \n",
      "   2    |  4940   |   1.778389   |     -      |     -     |   1.83   \n",
      "   2    |  4960   |   2.447457   |     -      |     -     |   1.83   \n",
      "   2    |  4980   |   2.478136   |     -      |     -     |   1.83   \n",
      "   2    |  4998   |   0.805649   |     -      |     -     |   1.66   \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   1.788034   |  2.005374  |   60.30   |  486.05  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)    # Set seed for reproducibility\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xPbbDrzeiwUj"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def bert_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LpkLVKIJlYWy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 10.92 GiB total capacity; 9.70 GiB already allocated; 369.50 MiB free; 9.94 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-691ba5c94c2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_train_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-d56baed159ef>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, epochs, evaluation)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# Perform a forward pass. This will return logits.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_attn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# Compute loss and accumulate the loss values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         )\n\u001b[0;32m--> 996\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 )\n\u001b[1;32m    584\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    586\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    473\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     ):\n\u001b[0;32m--> 402\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;31m# Mask heads if we want to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 10.92 GiB total capacity; 9.70 GiB already allocated; 369.50 MiB free; 9.94 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Concatenate the train set and the validation set\n",
    "full_train_data = torch.utils.data.ConcatDataset([train_data, val_data])\n",
    "full_train_sampler = RandomSampler(full_train_data)\n",
    "full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=32)\n",
    "\n",
    "# Train the Bert Classifier on the entire training data\n",
    "set_seed(42)\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "train(bert_classifier, full_train_dataloader, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIz4OzAPlc4Z"
   },
   "source": [
    "## Final Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mrY2M5jlevk"
   },
   "outputs": [],
   "source": [
    "# Run `preprocessing_for_bert` on the test set\n",
    "print('Tokenizing data...')\n",
    "test_inputs, test_masks = preprocessing_for_bert(df_test['Text'])\n",
    "\n",
    "test_labels = torch.tensor((df_test['Score']-1).to_numpy())\n",
    "\n",
    "\n",
    "# Create the DataLoader for our test set\n",
    "test_dataset = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(bert_classifier, test_dataloader)\n",
    "\n",
    "test_loss, test_accuracy = evaluate(bert_classifier, test_dataloader)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "A4T2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1655c36f82c840278690f1070561b072": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e510cb422654cc7af47d5fe066c5827": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29f751fc3d35416b88a2d6a524578b63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_487f9e5fe119446a897a3a95ac38c65d",
       "IPY_MODEL_a430ffcaba4145439221bddadc477815",
       "IPY_MODEL_aed444330bf64b29aa99f43fa835473e"
      ],
      "layout": "IPY_MODEL_7f163878271e48f1a758bc24d43e5978"
     }
    },
    "3d79ec161c8b4336b1daf0edb9235215": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3dda98c8377844138d4624931f054491",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7c50bf70806c478fa48df1df201ec733",
      "value": 28
     }
    },
    "3dda98c8377844138d4624931f054491": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "452f0140f7114b91adbfa09ecb3fb56c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "487f9e5fe119446a897a3a95ac38c65d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aebeca6d11564533b0e2885028ac2c32",
      "placeholder": "â",
      "style": "IPY_MODEL_8243c1bcf44146b999b03420bb2b8e66",
      "value": "Downloading: 100%"
     }
    },
    "4913a94fa16044e6b243aebcb64e6a31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4ba590880552402b97ae6c43a1b2d3c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e526c559a5bb4ec1ad552ada9a7a8958",
      "placeholder": "â",
      "style": "IPY_MODEL_8c919b6325354ec4abddc7aaebb445b4",
      "value": "Downloading: 100%"
     }
    },
    "50f6cf48e9584298bbc1222cae097058": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "599dce4954174f2b8909015d4c377290": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8330658fd0824df29ba8e8450b787497",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_abdfcfab69364a65a8233b0389266d01",
      "value": 231508
     }
    },
    "5b9737421df24fe0bdde038e8e14e8b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1b6df08e9b24e96a67a995509a2e10d",
      "placeholder": "â",
      "style": "IPY_MODEL_fe73813b431e4475bdb0972f16815b2a",
      "value": " 28.0/28.0 [00:00&lt;00:00, 707B/s]"
     }
    },
    "5e767bd5985044f888d84bd31230738c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_affa2a97c9c245d59365f74bce6b9772",
      "placeholder": "â",
      "style": "IPY_MODEL_af440b9acaff473e8269ae3944d693e9",
      "value": " 226k/226k [00:00&lt;00:00, 2.41MB/s]"
     }
    },
    "7959978aa50b4ebf9441f02615f1294d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c50bf70806c478fa48df1df201ec733": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7f163878271e48f1a758bc24d43e5978": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8243c1bcf44146b999b03420bb2b8e66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8330658fd0824df29ba8e8450b787497": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c919b6325354ec4abddc7aaebb445b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f82b402fd344929814a2dce4aacf700": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4ba590880552402b97ae6c43a1b2d3c5",
       "IPY_MODEL_3d79ec161c8b4336b1daf0edb9235215",
       "IPY_MODEL_5b9737421df24fe0bdde038e8e14e8b4"
      ],
      "layout": "IPY_MODEL_1655c36f82c840278690f1070561b072"
     }
    },
    "93e47265d4994aa789abed0d50def9b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e2b6e0cd20794e22940abeeb42cc8e96",
       "IPY_MODEL_599dce4954174f2b8909015d4c377290",
       "IPY_MODEL_5e767bd5985044f888d84bd31230738c"
      ],
      "layout": "IPY_MODEL_7959978aa50b4ebf9441f02615f1294d"
     }
    },
    "a430ffcaba4145439221bddadc477815": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e510cb422654cc7af47d5fe066c5827",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4913a94fa16044e6b243aebcb64e6a31",
      "value": 570
     }
    },
    "abdfcfab69364a65a8233b0389266d01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aebeca6d11564533b0e2885028ac2c32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aed444330bf64b29aa99f43fa835473e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7385c515c054a41be7896dbec63c823",
      "placeholder": "â",
      "style": "IPY_MODEL_50f6cf48e9584298bbc1222cae097058",
      "value": " 570/570 [00:00&lt;00:00, 14.3kB/s]"
     }
    },
    "af440b9acaff473e8269ae3944d693e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "affa2a97c9c245d59365f74bce6b9772": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c13f3c74b4804dc89c5c89ed9b81b202": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d1b6df08e9b24e96a67a995509a2e10d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7385c515c054a41be7896dbec63c823": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2b6e0cd20794e22940abeeb42cc8e96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_452f0140f7114b91adbfa09ecb3fb56c",
      "placeholder": "â",
      "style": "IPY_MODEL_c13f3c74b4804dc89c5c89ed9b81b202",
      "value": "Downloading: 100%"
     }
    },
    "e526c559a5bb4ec1ad552ada9a7a8958": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe73813b431e4475bdb0972f16815b2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
